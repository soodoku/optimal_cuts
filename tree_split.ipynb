{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83dcf944-e692-48ac-b846-680cbaf142ba",
   "metadata": {},
   "source": [
    "### Optimal Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f84b5bcd-5960-4840-be1b-6682a78489b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal bin edges: [-3.23105501 -2.34872711 -1.69677424 -1.33771819 -0.99379808 -0.74967471\n",
      " -0.49406621 -0.26091591 -0.03464736  0.18503929  0.39758199  0.62069392\n",
      "  0.86372635  1.13615036  1.46575928  2.13694978  3.57157922]\n",
      "MSE: 0.04942159608021452\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Generate the data as a thousand draws from a random normal distribution\n",
    "np.random.seed(123)\n",
    "data = np.random.normal(loc=0, scale=1, size=1000)\n",
    "\n",
    "# Function to recursively find optimal bins using Decision Tree with a specified maximum number of splits\n",
    "def find_optimal_bins(data, max_splits, bin_edges=None):\n",
    "    if bin_edges is None:\n",
    "        bin_edges = np.array([np.min(data), np.max(data)])\n",
    "    \n",
    "    # Create the predictor variable (data) and the response variable (data)\n",
    "    X = data[:, np.newaxis]  # Convert data to a 2D array\n",
    "    y = data\n",
    "\n",
    "    # Fit the Decision Tree Regressor\n",
    "    tree_model = DecisionTreeRegressor(max_leaf_nodes=max_splits + 1)\n",
    "    tree_model.fit(X, y)\n",
    "\n",
    "    # Get the bin edges from the Decision Tree splits\n",
    "    splits = np.sort(tree_model.tree_.threshold[tree_model.tree_.feature >= 0])\n",
    "    bin_edges = np.sort(np.unique(np.concatenate([bin_edges, splits])))\n",
    "\n",
    "    # If the number of splits is greater than or equal to the specified max_splits, return the bin edges\n",
    "    if len(bin_edges) - 1 >= max_splits:\n",
    "        return bin_edges\n",
    "    else:\n",
    "        # Recursively split further until reaching max_splits\n",
    "        return find_optimal_bins(data, max_splits, bin_edges)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE)\n",
    "def calculate_mse(data, bin_means, bin_edges):\n",
    "    binned_data = np.array([bin_means[np.digitize(val, bin_edges, right=True) - 1] for val in data])\n",
    "    return np.mean((data - binned_data)**2)\n",
    "\n",
    "# Set the maximum number of splits (bins - 1)\n",
    "max_splits = 15\n",
    "\n",
    "# Find the optimal bins using Decision Tree with a specified maximum number of splits\n",
    "bin_edges = find_optimal_bins(data, max_splits)\n",
    "\n",
    "# Calculate the bin means based on the data\n",
    "bin_means = np.array([(bin_edges[i] + bin_edges[i+1]) / 2 for i in range(len(bin_edges) - 1)])\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE)\n",
    "mse = calculate_mse(data, bin_means, bin_edges)\n",
    "\n",
    "print(\"Optimal bin edges:\", bin_edges)\n",
    "print(\"MSE:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfa9fbd-df98-4c5e-85bc-0977f620255c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
